{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, rows, label, features):\n",
    "        self.data = data\n",
    "        self.rows = rows\n",
    "        self.l_child = None\n",
    "        self.r_child = None\n",
    "        self.parent = None\n",
    "        self.label = label\n",
    "        self.features = features\n",
    "        self.binned_features\n",
    "        \n",
    "    def split(self):\n",
    "        ''' iterate through each existing feature and create two children based on entropy'''\n",
    "        entropies = []\n",
    "        for feature in self.features:\n",
    "            entropies.append((self.calculateEntropy(feature), feature))\n",
    "    \n",
    "    def calculateEntropy(self, feature):\n",
    "        ''' for the given feature, calculate the entropy'''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.head = Node()\n",
    "        \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HW3_Data.txt', delimiter='\\t')\n",
    "# print(df)\n",
    "\n",
    "df['Location Type'] = df['Location Type'].map({'Office': 0, 'Warehouse': 1})\n",
    "\n",
    "train = df[:2800]\n",
    "test = df[-200:]\n",
    "# print(df['Location Type'])\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train[['Distance_Feature', 'Speeding_Feature', 'Location Type']], train['OSHA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "results = clf.predict(test[['Distance_Feature', 'Speeding_Feature', 'Location Type']])\n",
    "actual = test['OSHA']\n",
    "print(len(actual))\n",
    "tups = zip(results, actual)\n",
    "# print(list(tups))\n",
    "right = 0\n",
    "for tup in tups:\n",
    "    if tup[0] == tup[1]:\n",
    "        right += 1\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.95999999999999996, 0.95999999999999996, 0.95999999999999996, 0.95999999999999996)\n",
      "(0.96499999999999997, 0.96499999999999997, 0.96499999999999997, 0.96499999999999997)\n",
      "(0.96499999999999997, 0.96499999999999997, 0.96499999999999997, 0.96499999999999997)\n",
      "(0.97499999999999998, 0.97499999999999998, 0.97499999999999998, 0.97499999999999998)\n",
      "(0.98499999999999999, 0.98499999999999999, 0.98499999999999999, 0.98499999999999999)\n",
      "(0.98999999999999999, 0.98999999999999999, 0.98999999999999999, 0.98999999999999999)\n",
      "(0.98999999999999999, 0.98999999999999999, 0.98999999999999999, 0.98999999999999999)\n",
      "(0.99250000000000005, 0.99250000000000005, 0.99250000000000005, 0.99250000000000005)\n",
      "(0.99250000000000005, 0.99250000000000005, 0.99250000000000005, 0.99250000000000005)\n",
      "(0.995, 0.995, 0.995, 0.995)\n"
     ]
    }
   ],
   "source": [
    "def ten_fold_validation():\n",
    "    df = pd.read_csv('HW3_Data.txt', delimiter='\\t')\n",
    "\n",
    "    df['Location Type'] = df['Location Type'].map({'Office': 0, 'Warehouse': 1})\n",
    "\n",
    "    test_size = 400\n",
    "    start = 0\n",
    "    \n",
    "    stats = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        test = df[start:start+test_size]\n",
    "        train = df[~df['HeatMiser_ID'].isin(test['HeatMiser_ID'])].dropna()\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        clf = clf.fit(train[['Distance_Feature', 'Speeding_Feature', 'Location Type']], train['OSHA'])\n",
    "            \n",
    "        results = clf.predict(test[['Distance_Feature', 'Speeding_Feature', 'Location Type']])\n",
    "        actual = test['OSHA']\n",
    "        tups = zip(results, actual)\n",
    "        # print(list(tups))\n",
    "        right = 0\n",
    "        for tup in tups:\n",
    "            if tup[0] == tup[1]:\n",
    "                right += 1\n",
    "        precision = precision_score(actual, results, average='micro')\n",
    "        recall = recall_score(actual, results, average='micro')\n",
    "        accuracy = accuracy_score(actual, results)\n",
    "        f1 = f1_score(actual,results, average='micro')\n",
    "        stats.append((precision, recall, accuracy, f1))\n",
    "        start += test_size\n",
    "    stats = sorted(stats, key = lambda x: x[3])\n",
    "    for s in stats:\n",
    "        print(s)\n",
    "ten_fold_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300.0, 2700.0)\n",
      "(600.0, 5400.0)\n",
      "(900.0, 8100.0)\n",
      "(1200.0, 10800.0)\n",
      "(1500.0, 13500.0)\n",
      "(1800.0, 16200.0)\n",
      "(2100.0, 18900.0)\n",
      "(2400.0, 21600.0)\n",
      "(2700.0, 24300.0)\n",
      "(3000.0, 27000.0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
